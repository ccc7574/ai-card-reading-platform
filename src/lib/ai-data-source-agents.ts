// AI Agenté©±åŠ¨çš„æ™ºèƒ½æ•°æ®æºå¤„ç†ç³»ç»Ÿ
import { OpenAI } from 'openai'
import { GoogleGenerativeAI } from '@google/generative-ai'
import { ragEngine } from './rag-engine'

export interface DataSource {
  id: string
  name: string
  url: string
  type: 'rss' | 'api' | 'scraping' | 'webhook'
  category: string
  priority: number
  updateFrequency: number // å°æ—¶
  lastUpdated: Date
  isActive: boolean
  metadata: {
    language: string
    region: string
    contentType: string[]
    qualityScore: number
    reliability: number
  }
}

export interface RawContent {
  id: string
  sourceId: string
  title: string
  content: string
  url: string
  publishedAt: Date
  author?: string
  metadata: Record<string, any>
}

export interface ProcessedContent {
  id: string
  title: string
  summary: string
  content: string
  category: string
  tags: string[]
  difficulty: 'beginner' | 'intermediate' | 'advanced' | 'expert'
  readingTime: number
  qualityScore: number
  sentiment: 'positive' | 'neutral' | 'negative'
  keyInsights: string[]
  relatedTopics: string[]
  actionableItems: string[]
  sourceId: string
  publishedAt: Date
  processedAt: Date
}

// å†…å®¹æŠ“å–Agent
class ContentFetchAgent {
  private openai: OpenAI
  private name = 'ContentFetchAgent'

  constructor() {
    this.openai = new OpenAI({ apiKey: process.env.OPENAI_API_KEY })
  }

  async fetchFromSource(source: DataSource): Promise<RawContent[]> {
    console.log(`ğŸ•·ï¸ ${this.name} å¼€å§‹æŠ“å–: ${source.name}`)

    try {
      switch (source.type) {
        case 'rss':
          return await this.fetchRSS(source)
        case 'api':
          return await this.fetchAPI(source)
        case 'scraping':
          return await this.fetchScraping(source)
        default:
          console.warn(`ä¸æ”¯æŒçš„æ•°æ®æºç±»å‹: ${source.type}`)
          return []
      }
    } catch (error) {
      console.error(`${this.name} æŠ“å–å¤±è´¥:`, error)
      return []
    }
  }

  private async fetchRSS(source: DataSource): Promise<RawContent[]> {
    // æ¨¡æ‹ŸRSSæŠ“å–
    const mockContent: RawContent[] = [
      {
        id: `${source.id}_${Date.now()}_1`,
        sourceId: source.id,
        title: `${source.name}æœ€æ–°æ–‡ç« ï¼šAIæŠ€æœ¯å‘å±•è¶‹åŠ¿`,
        content: 'äººå·¥æ™ºèƒ½æŠ€æœ¯æ­£åœ¨å¿«é€Ÿå‘å±•ï¼Œç‰¹åˆ«æ˜¯åœ¨å¤§è¯­è¨€æ¨¡å‹ã€è®¡ç®—æœºè§†è§‰å’Œè‡ªåŠ¨åŒ–é¢†åŸŸ...',
        url: `${source.url}/article-1`,
        publishedAt: new Date(),
        author: 'æŠ€æœ¯ä¸“å®¶',
        metadata: { type: 'article', language: 'zh' }
      },
      {
        id: `${source.id}_${Date.now()}_2`,
        sourceId: source.id,
        title: `${source.name}æ·±åº¦åˆ†æï¼šæœºå™¨å­¦ä¹ åœ¨å®é™…åº”ç”¨ä¸­çš„æŒ‘æˆ˜`,
        content: 'æœºå™¨å­¦ä¹ æŠ€æœ¯è™½ç„¶å‘å±•è¿…é€Ÿï¼Œä½†åœ¨å®é™…åº”ç”¨ä¸­ä»é¢ä¸´æ•°æ®è´¨é‡ã€æ¨¡å‹è§£é‡Šæ€§ç­‰æŒ‘æˆ˜...',
        url: `${source.url}/article-2`,
        publishedAt: new Date(Date.now() - 3600000),
        author: 'MLç ”ç©¶å‘˜',
        metadata: { type: 'analysis', language: 'zh' }
      }
    ]

    return mockContent
  }

  private async fetchAPI(source: DataSource): Promise<RawContent[]> {
    // æ¨¡æ‹ŸAPIæŠ“å–
    return []
  }

  private async fetchScraping(source: DataSource): Promise<RawContent[]> {
    // æ¨¡æ‹Ÿç½‘é¡µæŠ“å–
    return []
  }
}

// å†…å®¹è´¨é‡è¯„ä¼°Agent
class ContentQualityAgent {
  private openai: OpenAI
  private name = 'ContentQualityAgent'

  constructor() {
    this.openai = new OpenAI({ apiKey: process.env.OPENAI_API_KEY })
  }

  async assessQuality(content: RawContent): Promise<number> {
    console.log(`ğŸ“Š ${this.name} è¯„ä¼°è´¨é‡: ${content.title}`)

    try {
      const prompt = `
ä½œä¸ºå†…å®¹è´¨é‡è¯„ä¼°ä¸“å®¶ï¼Œè¯·è¯„ä¼°ä»¥ä¸‹å†…å®¹çš„è´¨é‡ï¼š

æ ‡é¢˜: ${content.title}
å†…å®¹: ${content.content.substring(0, 1000)}
ä½œè€…: ${content.author || 'æœªçŸ¥'}

è¯·ä»ä»¥ä¸‹ç»´åº¦è¯„ä¼°è´¨é‡ï¼ˆ0-10åˆ†ï¼‰ï¼š
1. å†…å®¹åŸåˆ›æ€§å’Œæ·±åº¦
2. ä¿¡æ¯å‡†ç¡®æ€§å’Œå¯ä¿¡åº¦
3. å†™ä½œè´¨é‡å’Œé€»è¾‘æ€§
4. å®ç”¨æ€§å’Œä»·å€¼
5. æ—¶æ•ˆæ€§å’Œç›¸å…³æ€§

è¿”å›JSONæ ¼å¼ï¼š
{
  "overallScore": 8.5,
  "dimensions": {
    "originality": 8,
    "accuracy": 9,
    "writing": 8,
    "utility": 9,
    "relevance": 8
  },
  "reasoning": "è¯„ä¼°ç†ç”±",
  "recommendation": "accept|review|reject"
}
`

      const response = await this.openai.chat.completions.create({
        model: 'gpt-4',
        messages: [{ role: 'user', content: prompt }],
        temperature: 0.3
      })

      const assessment = JSON.parse(response.choices[0].message.content || '{"overallScore": 5}')
      return assessment.overallScore / 10 // è½¬æ¢ä¸º0-1èŒƒå›´

    } catch (error) {
      console.error(`${this.name} è´¨é‡è¯„ä¼°å¤±è´¥:`, error)
      return 0.5 // é»˜è®¤ä¸­ç­‰è´¨é‡
    }
  }

  async detectDuplicates(content: RawContent, existingContent: ProcessedContent[]): Promise<boolean> {
    try {
      // ä½¿ç”¨RAGå¼•æ“æ£€æµ‹é‡å¤å†…å®¹
      const ragResponse = await ragEngine.search({
        query: content.title,
        options: { topK: 5, threshold: 0.8 }
      })

      // å¦‚æœæ‰¾åˆ°é«˜ç›¸ä¼¼åº¦çš„å†…å®¹ï¼Œè®¤ä¸ºæ˜¯é‡å¤
      return ragResponse.results.length > 0 && ragResponse.confidence > 0.8

    } catch (error) {
      console.error('é‡å¤æ£€æµ‹å¤±è´¥:', error)
      return false
    }
  }
}

// å†…å®¹å¤„ç†å’Œå¢å¼ºAgent
class ContentProcessingAgent {
  private openai: OpenAI
  private gemini: GoogleGenerativeAI
  private name = 'ContentProcessingAgent'

  constructor() {
    this.openai = new OpenAI({ apiKey: process.env.OPENAI_API_KEY })
    this.gemini = new GoogleGenerativeAI(process.env.GEMINI_API_KEY || '')
  }

  async processContent(rawContent: RawContent): Promise<ProcessedContent> {
    console.log(`âš™ï¸ ${this.name} å¤„ç†å†…å®¹: ${rawContent.title}`)

    try {
      // å¹¶è¡Œå¤„ç†å¤šä¸ªä»»åŠ¡
      const [
        summary,
        categoryAndTags,
        difficulty,
        readingTime,
        sentiment,
        insights,
        relatedTopics,
        actionableItems
      ] = await Promise.all([
        this.generateSummary(rawContent),
        this.categorizeAndTag(rawContent),
        this.assessDifficulty(rawContent),
        this.calculateReadingTime(rawContent),
        this.analyzeSentiment(rawContent),
        this.extractKeyInsights(rawContent),
        this.findRelatedTopics(rawContent),
        this.extractActionableItems(rawContent)
      ])

      const processedContent: ProcessedContent = {
        id: rawContent.id,
        title: rawContent.title,
        summary,
        content: rawContent.content,
        category: categoryAndTags.category,
        tags: categoryAndTags.tags,
        difficulty,
        readingTime,
        qualityScore: 0.8, // å°†ç”±è´¨é‡è¯„ä¼°Agentè®¾ç½®
        sentiment,
        keyInsights,
        relatedTopics,
        actionableItems,
        sourceId: rawContent.sourceId,
        publishedAt: rawContent.publishedAt,
        processedAt: new Date()
      }

      return processedContent

    } catch (error) {
      console.error(`${this.name} å†…å®¹å¤„ç†å¤±è´¥:`, error)
      throw error
    }
  }

  private async generateSummary(content: RawContent): Promise<string> {
    try {
      const prompt = `
è¯·ä¸ºä»¥ä¸‹å†…å®¹ç”Ÿæˆä¸€ä¸ªç®€æ´è€Œå…¨é¢çš„æ‘˜è¦ï¼ˆ100-150å­—ï¼‰ï¼š

æ ‡é¢˜: ${content.title}
å†…å®¹: ${content.content}

è¦æ±‚ï¼š
1. çªå‡ºæ ¸å¿ƒè§‚ç‚¹å’Œå…³é”®ä¿¡æ¯
2. ä¿æŒå®¢è§‚å’Œå‡†ç¡®
3. é€‚åˆå¿«é€Ÿé˜…è¯»
4. å¸å¼•è¯»è€…å…´è¶£
`

      const response = await this.openai.chat.completions.create({
        model: 'gpt-4',
        messages: [{ role: 'user', content: prompt }],
        temperature: 0.4
      })

      return response.choices[0].message.content || 'å†…å®¹æ‘˜è¦ç”Ÿæˆå¤±è´¥'

    } catch (error) {
      console.error('æ‘˜è¦ç”Ÿæˆå¤±è´¥:', error)
      return content.content.substring(0, 150) + '...'
    }
  }

  private async categorizeAndTag(content: RawContent): Promise<{ category: string; tags: string[] }> {
    try {
      const prompt = `
è¯·ä¸ºä»¥ä¸‹å†…å®¹è¿›è¡Œåˆ†ç±»å’Œæ ‡ç­¾æå–ï¼š

æ ‡é¢˜: ${content.title}
å†…å®¹: ${content.content.substring(0, 1000)}

è¿”å›JSONæ ¼å¼ï¼š
{
  "category": "ä¸»è¦åˆ†ç±»ï¼ˆtech/ai/business/design/science/programmingç­‰ï¼‰",
  "tags": ["æ ‡ç­¾1", "æ ‡ç­¾2", "æ ‡ç­¾3", "æ ‡ç­¾4", "æ ‡ç­¾5"]
}

è¦æ±‚ï¼š
1. åˆ†ç±»è¦å‡†ç¡®ä¸”å…·ä½“
2. æ ‡ç­¾è¦ç›¸å…³ä¸”æœ‰ç”¨
3. åŒ…å«æŠ€æœ¯æœ¯è¯­å’Œæ¦‚å¿µ
4. 5-8ä¸ªæ ‡ç­¾
`

      const response = await this.openai.chat.completions.create({
        model: 'gpt-4',
        messages: [{ role: 'user', content: prompt }],
        temperature: 0.3
      })

      const result = JSON.parse(response.choices[0].message.content || '{"category": "tech", "tags": []}')
      return {
        category: result.category || 'tech',
        tags: Array.isArray(result.tags) ? result.tags : []
      }

    } catch (error) {
      console.error('åˆ†ç±»æ ‡ç­¾å¤±è´¥:', error)
      return { category: 'tech', tags: [] }
    }
  }

  private async assessDifficulty(content: RawContent): Promise<'beginner' | 'intermediate' | 'advanced' | 'expert'> {
    try {
      const prompt = `
è¯„ä¼°ä»¥ä¸‹å†…å®¹çš„éš¾åº¦çº§åˆ«ï¼š

æ ‡é¢˜: ${content.title}
å†…å®¹: ${content.content.substring(0, 800)}

è¯·æ ¹æ®ä»¥ä¸‹æ ‡å‡†è¯„ä¼°ï¼š
- beginner: åŸºç¡€æ¦‚å¿µï¼Œæ— éœ€ä¸“ä¸šèƒŒæ™¯
- intermediate: éœ€è¦ä¸€å®šåŸºç¡€çŸ¥è¯†
- advanced: éœ€è¦æ·±å…¥çš„ä¸“ä¸šçŸ¥è¯†
- expert: éœ€è¦ä¸“å®¶çº§åˆ«çš„ç†è§£

åªè¿”å›éš¾åº¦çº§åˆ«ï¼Œä¸è¦å…¶ä»–å†…å®¹ã€‚
`

      const response = await this.openai.chat.completions.create({
        model: 'gpt-4',
        messages: [{ role: 'user', content: prompt }],
        temperature: 0.2
      })

      const difficulty = response.choices[0].message.content?.trim().toLowerCase()
      
      if (['beginner', 'intermediate', 'advanced', 'expert'].includes(difficulty || '')) {
        return difficulty as any
      }
      
      return 'intermediate'

    } catch (error) {
      console.error('éš¾åº¦è¯„ä¼°å¤±è´¥:', error)
      return 'intermediate'
    }
  }

  private calculateReadingTime(content: RawContent): number {
    // åŸºäºå­—æ•°ä¼°ç®—é˜…è¯»æ—¶é—´ï¼ˆä¸­æ–‡çº¦300å­—/åˆ†é’Ÿï¼‰
    const wordCount = content.content.length
    return Math.ceil(wordCount / 300)
  }

  private async analyzeSentiment(content: RawContent): Promise<'positive' | 'neutral' | 'negative'> {
    try {
      const prompt = `
åˆ†æä»¥ä¸‹å†…å®¹çš„æƒ…æ„Ÿå€¾å‘ï¼š

æ ‡é¢˜: ${content.title}
å†…å®¹: ${content.content.substring(0, 500)}

è¿”å›ä»¥ä¸‹ä¹‹ä¸€ï¼š
- positive: ç§¯æã€ä¹è§‚ã€æ­£é¢
- neutral: ä¸­æ€§ã€å®¢è§‚
- negative: æ¶ˆæã€æ‚²è§‚ã€è´Ÿé¢

åªè¿”å›æƒ…æ„Ÿç±»å‹ï¼Œä¸è¦å…¶ä»–å†…å®¹ã€‚
`

      const response = await this.openai.chat.completions.create({
        model: 'gpt-4',
        messages: [{ role: 'user', content: prompt }],
        temperature: 0.2
      })

      const sentiment = response.choices[0].message.content?.trim().toLowerCase()
      
      if (['positive', 'neutral', 'negative'].includes(sentiment || '')) {
        return sentiment as any
      }
      
      return 'neutral'

    } catch (error) {
      console.error('æƒ…æ„Ÿåˆ†æå¤±è´¥:', error)
      return 'neutral'
    }
  }

  private async extractKeyInsights(content: RawContent): Promise<string[]> {
    try {
      const prompt = `
ä»ä»¥ä¸‹å†…å®¹ä¸­æå–3-5ä¸ªå…³é”®æ´å¯Ÿï¼š

æ ‡é¢˜: ${content.title}
å†…å®¹: ${content.content}

è¿”å›JSONæ•°ç»„æ ¼å¼ï¼š["æ´å¯Ÿ1", "æ´å¯Ÿ2", "æ´å¯Ÿ3"]

è¦æ±‚ï¼š
1. æ¯ä¸ªæ´å¯Ÿéƒ½æ˜¯ç‹¬ç«‹çš„è¦ç‚¹
2. çªå‡ºé‡è¦å‘ç°æˆ–è§‚ç‚¹
3. ç®€æ´æ˜äº†ï¼Œæ˜“äºç†è§£
4. å…·æœ‰å®é™…ä»·å€¼
`

      const response = await this.openai.chat.completions.create({
        model: 'gpt-4',
        messages: [{ role: 'user', content: prompt }],
        temperature: 0.4
      })

      const insights = JSON.parse(response.choices[0].message.content || '[]')
      return Array.isArray(insights) ? insights : []

    } catch (error) {
      console.error('å…³é”®æ´å¯Ÿæå–å¤±è´¥:', error)
      return []
    }
  }

  private async findRelatedTopics(content: RawContent): Promise<string[]> {
    try {
      const prompt = `
åŸºäºä»¥ä¸‹å†…å®¹ï¼Œè¯†åˆ«ç›¸å…³ä¸»é¢˜ï¼š

æ ‡é¢˜: ${content.title}
å†…å®¹: ${content.content.substring(0, 800)}

è¿”å›JSONæ•°ç»„æ ¼å¼ï¼š["ç›¸å…³ä¸»é¢˜1", "ç›¸å…³ä¸»é¢˜2", "ç›¸å…³ä¸»é¢˜3"]

è¦æ±‚ï¼š
1. 3-5ä¸ªç›¸å…³ä¸»é¢˜
2. åŒ…å«æŠ€æœ¯æ¦‚å¿µå’Œé¢†åŸŸ
3. æœ‰åŠ©äºæ‰©å±•é˜…è¯»
4. ä¸åŸå†…å®¹ç›¸å…³ä½†ä¸é‡å¤
`

      const response = await this.openai.chat.completions.create({
        model: 'gpt-4',
        messages: [{ role: 'user', content: prompt }],
        temperature: 0.4
      })

      const topics = JSON.parse(response.choices[0].message.content || '[]')
      return Array.isArray(topics) ? topics : []

    } catch (error) {
      console.error('ç›¸å…³ä¸»é¢˜æå–å¤±è´¥:', error)
      return []
    }
  }

  private async extractActionableItems(content: RawContent): Promise<string[]> {
    try {
      const prompt = `
ä»ä»¥ä¸‹å†…å®¹ä¸­æå–å¯æ‰§è¡Œçš„è¡ŒåŠ¨é¡¹ï¼š

æ ‡é¢˜: ${content.title}
å†…å®¹: ${content.content}

è¿”å›JSONæ•°ç»„æ ¼å¼ï¼š["è¡ŒåŠ¨é¡¹1", "è¡ŒåŠ¨é¡¹2", "è¡ŒåŠ¨é¡¹3"]

è¦æ±‚ï¼š
1. å…·ä½“å¯æ‰§è¡Œçš„å»ºè®®æˆ–æ­¥éª¤
2. å¯¹è¯»è€…æœ‰å®é™…ä»·å€¼
3. ç®€æ´æ˜äº†
4. 2-4ä¸ªè¡ŒåŠ¨é¡¹
`

      const response = await this.openai.chat.completions.create({
        model: 'gpt-4',
        messages: [{ role: 'user', content: prompt }],
        temperature: 0.4
      })

      const actions = JSON.parse(response.choices[0].message.content || '[]')
      return Array.isArray(actions) ? actions : []

    } catch (error) {
      console.error('è¡ŒåŠ¨é¡¹æå–å¤±è´¥:', error)
      return []
    }
  }
}

// æ™ºèƒ½æ•°æ®æºç®¡ç†ç³»ç»Ÿ
export class AIDataSourceManager {
  private static instance: AIDataSourceManager
  private fetchAgent: ContentFetchAgent
  private qualityAgent: ContentQualityAgent
  private processingAgent: ContentProcessingAgent
  private dataSources = new Map<string, DataSource>()
  private processedContent: ProcessedContent[] = []

  private constructor() {
    this.fetchAgent = new ContentFetchAgent()
    this.qualityAgent = new ContentQualityAgent()
    this.processingAgent = new ContentProcessingAgent()
    this.initializeDataSources()
  }

  public static getInstance(): AIDataSourceManager {
    if (!AIDataSourceManager.instance) {
      AIDataSourceManager.instance = new AIDataSourceManager()
    }
    return AIDataSourceManager.instance
  }

  private initializeDataSources() {
    const sources: DataSource[] = [
      {
        id: 'techcrunch',
        name: 'TechCrunch',
        url: 'https://techcrunch.com/feed/',
        type: 'rss',
        category: 'tech',
        priority: 9,
        updateFrequency: 2,
        lastUpdated: new Date(),
        isActive: true,
        metadata: {
          language: 'en',
          region: 'global',
          contentType: ['news', 'analysis'],
          qualityScore: 0.9,
          reliability: 0.95
        }
      },
      {
        id: 'arxiv_ai',
        name: 'arXiv AI Papers',
        url: 'https://arxiv.org/rss/cs.AI',
        type: 'rss',
        category: 'ai',
        priority: 8,
        updateFrequency: 6,
        lastUpdated: new Date(),
        isActive: true,
        metadata: {
          language: 'en',
          region: 'global',
          contentType: ['research', 'paper'],
          qualityScore: 0.95,
          reliability: 0.98
        }
      },
      {
        id: 'mit_tech_review',
        name: 'MIT Technology Review',
        url: 'https://www.technologyreview.com/feed/',
        type: 'rss',
        category: 'tech',
        priority: 9,
        updateFrequency: 4,
        lastUpdated: new Date(),
        isActive: true,
        metadata: {
          language: 'en',
          region: 'global',
          contentType: ['analysis', 'feature'],
          qualityScore: 0.92,
          reliability: 0.96
        }
      }
    ]

    sources.forEach(source => {
      this.dataSources.set(source.id, source)
    })

    console.log(`ğŸ“š åˆå§‹åŒ–äº† ${sources.length} ä¸ªæ•°æ®æº`)
  }

  // æ™ºèƒ½å†…å®¹æ›´æ–°
  public async updateAllSources(): Promise<ProcessedContent[]> {
    console.log('ğŸ”„ å¼€å§‹æ™ºèƒ½å†…å®¹æ›´æ–°...')
    
    const newContent: ProcessedContent[] = []

    for (const [sourceId, source] of this.dataSources) {
      if (!source.isActive) continue

      try {
        // æ£€æŸ¥æ˜¯å¦éœ€è¦æ›´æ–°
        const hoursSinceUpdate = (Date.now() - source.lastUpdated.getTime()) / (1000 * 60 * 60)
        if (hoursSinceUpdate < source.updateFrequency) {
          continue
        }

        console.log(`ğŸ“¡ æ›´æ–°æ•°æ®æº: ${source.name}`)

        // 1. æŠ“å–åŸå§‹å†…å®¹
        const rawContents = await this.fetchAgent.fetchFromSource(source)

        for (const rawContent of rawContents) {
          // 2. è´¨é‡è¯„ä¼°
          const qualityScore = await this.qualityAgent.assessQuality(rawContent)
          
          // 3. é‡å¤æ£€æµ‹
          const isDuplicate = await this.qualityAgent.detectDuplicates(rawContent, this.processedContent)
          
          if (qualityScore > 0.6 && !isDuplicate) {
            // 4. å†…å®¹å¤„ç†å’Œå¢å¼º
            const processedContent = await this.processingAgent.processContent(rawContent)
            processedContent.qualityScore = qualityScore

            // 5. å‘é‡åŒ–å¹¶å­˜å‚¨åˆ°RAGå¼•æ“
            await ragEngine.processDocument(processedContent)

            newContent.push(processedContent)
            this.processedContent.push(processedContent)
          }
        }

        // æ›´æ–°æ•°æ®æºçš„æœ€åæ›´æ–°æ—¶é—´
        source.lastUpdated = new Date()

      } catch (error) {
        console.error(`æ•°æ®æº ${source.name} æ›´æ–°å¤±è´¥:`, error)
      }
    }

    console.log(`âœ… å†…å®¹æ›´æ–°å®Œæˆï¼Œæ–°å¢ ${newContent.length} ç¯‡å†…å®¹`)
    return newContent
  }

  // è·å–æ•°æ®æºçŠ¶æ€
  public getDataSourceStatus() {
    const sources = Array.from(this.dataSources.values())
    
    return {
      total: sources.length,
      active: sources.filter(s => s.isActive).length,
      byCategory: sources.reduce((acc, source) => {
        acc[source.category] = (acc[source.category] || 0) + 1
        return acc
      }, {} as Record<string, number>),
      averageQuality: sources.reduce((sum, s) => sum + s.metadata.qualityScore, 0) / sources.length,
      lastUpdated: Math.max(...sources.map(s => s.lastUpdated.getTime())),
      totalContent: this.processedContent.length
    }
  }

  // æ·»åŠ æ–°æ•°æ®æº
  public addDataSource(source: Omit<DataSource, 'id' | 'lastUpdated'>): string {
    const id = `source_${Date.now()}_${Math.random().toString(36).substr(2, 9)}`
    const newSource: DataSource = {
      ...source,
      id,
      lastUpdated: new Date()
    }
    
    this.dataSources.set(id, newSource)
    console.log(`â• æ·»åŠ æ–°æ•°æ®æº: ${source.name}`)
    
    return id
  }

  // è·å–å¤„ç†åçš„å†…å®¹
  public getProcessedContent(limit?: number): ProcessedContent[] {
    const sorted = this.processedContent
      .sort((a, b) => b.processedAt.getTime() - a.processedAt.getTime())
    
    return limit ? sorted.slice(0, limit) : sorted
  }

  // è·å–ç»Ÿè®¡ä¿¡æ¯
  public getStats() {
    return {
      dataSources: this.getDataSourceStatus(),
      ragEngine: ragEngine.getStats(),
      processing: {
        totalProcessed: this.processedContent.length,
        averageQuality: this.processedContent.reduce((sum, c) => sum + c.qualityScore, 0) / this.processedContent.length,
        categoryDistribution: this.processedContent.reduce((acc, content) => {
          acc[content.category] = (acc[content.category] || 0) + 1
          return acc
        }, {} as Record<string, number>)
      },
      lastUpdated: new Date().toISOString()
    }
  }
}

// å¯¼å‡ºå•ä¾‹å®ä¾‹
export const aiDataSourceManager = AIDataSourceManager.getInstance()
